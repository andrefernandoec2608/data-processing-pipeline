{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b2795a-ce06-45cc-a95b-79fc08915931",
   "metadata": {},
   "source": [
    "# 0) Introduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68f687cd-3464-446a-9e1c-300c484f9e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment1 made by Andre Llumiquinga for \n",
      "End-to-end Data Science lifecycle project showcasing structured project organization, reproducible workflows, and a modular data processing pipeline.\n"
     ]
    }
   ],
   "source": [
    "print('Assignment1 made by Andre Llumiquinga for ')\n",
    "print(\"End-to-end Data Science lifecycle project showcasing structured project organization, reproducible workflows, and a modular data processing pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71a52b-c775-4019-bf5a-8a6feb60d771",
   "metadata": {},
   "source": [
    "# 1) Setup paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e40b78-f0c2-4ce7-8c1e-f9f2d7b29131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.7\n",
      "Platform: Windows-11-10.0.26100-SP0\n",
      "pandas: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print('Python:', sys.version.split()[0])\n",
    "print('Platform:', platform.platform())\n",
    "print('pandas:', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7008a5a2-7b65-4ba7-8536-f13dfb1567df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/DyFer/Documents/ELTE/2Semester/ITDS/A01/data-processing-pipeline/assignment1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd() / \"assignment1\"\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "DATA_INTERIM = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "REPORTS = PROJECT_ROOT / \"reports\"\n",
    "\n",
    "for p in [DATA_RAW, DATA_INTERIM, DATA_PROCESSED, REPORTS]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT: \")\n",
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d99adc8-9d55-4c25-8ce9-5da09edb78bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas==2.3.3\n",
      "numpy==2.3.4\n",
      "openpyxl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Freeze a minimal requirements file (teaching demo)\n",
    "requirements = [\n",
    "    f\"pandas=={pd.__version__}\",\n",
    "    f\"numpy=={np.__version__}\",\n",
    "    \"openpyxl\"  # needed for reading/writing .xlsx with pandas\n",
    "]\n",
    "(PROJECT_ROOT / \"requirements.txt\").write_text(\"\\n\".join(requirements) + \"\\n\")\n",
    "print((PROJECT_ROOT / \"requirements.txt\").read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89d60a-5622-4c36-8a38-ffab448b9f33",
   "metadata": {},
   "source": [
    "# 2) Load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bbd6af4-b2a9-4fbc-94ed-951c8773cdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame loaded done!\n"
     ]
    }
   ],
   "source": [
    "# --- Dataset filename  ---\n",
    "raw_csv_filename = \"synthetic_dataset.csv\"\n",
    "\n",
    "# --- Build full path using DATA_RAW ---\n",
    "raw_csv_path = DATA_RAW / raw_csv_filename\n",
    "\n",
    "# --- Read CSV ---\n",
    "df_csv = pd.read_csv(raw_csv_path)\n",
    "\n",
    "print(\"Data Frame loaded done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd2e93-4d45-4208-9d48-47c3e1a7d31b",
   "metadata": {},
   "source": [
    "# 3) Check :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd424df-5ab6-4243-9d09-8448454124d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== SHAPE =====\n",
      "(4362, 5)\n",
      "\n",
      "===== HEAD =====\n",
      "  Category   Price    Rating         Stock  Discount\n",
      "0      NaN  5548.0  1.870322           NaN       0.0\n",
      "1      NaN  3045.0  4.757798           NaN      38.0\n",
      "2      NaN  4004.0       NaN      In Stock       0.0\n",
      "3      NaN  4808.0  1.492085           NaN      33.0\n",
      "4      NaN  1817.0       NaN  Out of Stock      23.0\n",
      "\n",
      "===== INFO =====\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4362 entries, 0 to 4361\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Category  1614 non-null   object \n",
      " 1   Price     4188 non-null   float64\n",
      " 2   Rating    2312 non-null   float64\n",
      " 3   Stock     3010 non-null   object \n",
      " 4   Discount  3970 non-null   float64\n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 170.5+ KB\n",
      "\n",
      "===== MISSING VALUES SUMMARY =====\n",
      "          missing_count  missing_percentage\n",
      "Category           2748           62.998624\n",
      "Price               174            3.988996\n",
      "Rating             2050           46.996790\n",
      "Stock              1352           30.994956\n",
      "Discount            392            8.986703\n",
      "\n",
      "===== DUPLICATES COUNT =====\n",
      "Number of duplicate rows: 15\n"
     ]
    }
   ],
   "source": [
    "# --- Basic checks ---\n",
    "print(\"===== SHAPE =====\")\n",
    "print(df_csv.shape)\n",
    "\n",
    "print(\"\\n===== HEAD =====\")\n",
    "print(df_csv.head())\n",
    "\n",
    "print(\"\\n===== INFO =====\")\n",
    "df_csv.info()\n",
    "\n",
    "print(\"\\n===== MISSING VALUES SUMMARY =====\")\n",
    "missing_summary = df_csv.isna().sum().to_frame(name=\"missing_count\")\n",
    "missing_summary[\"missing_percentage\"] = (\n",
    "    missing_summary[\"missing_count\"] / len(df_csv) * 100\n",
    ")\n",
    "print(missing_summary)\n",
    "\n",
    "print(\"\\n===== DUPLICATES COUNT =====\")\n",
    "duplicates_count = df_csv.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicates_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a933e-1735-433a-b12d-5ebc2d79f55f",
   "metadata": {},
   "source": [
    "# 4) Data Preparation :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408d812-df5d-410a-8bfc-e0a555fc94a8",
   "metadata": {},
   "source": [
    "## 4.1) Create function for Data Cleaning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9afe8a50-7d8f-4c88-8aa4-9625df69c496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean function created!\n"
     ]
    }
   ],
   "source": [
    "def clean_mydata(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # --- Make a copy to avoid modifying original ---\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1️⃣ Rename columns (lowercase + snake_case style)\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\")\n",
    "    )\n",
    "\n",
    "    # 2️⃣ Remove rows with missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # 3️⃣ Drop exact duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "print('Clean function created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01517cd-3c63-4faa-81e2-cdfaf689c709",
   "metadata": {},
   "source": [
    "## 4.2) Create function for Data Transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5230286-cb97-4618-8cad-fb7ea2e6d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation function created!\n"
     ]
    }
   ],
   "source": [
    "def transformation_mydata(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # --- Make a copy to avoid modifying original ---\n",
    "    df = df.copy()\n",
    "\n",
    "    # 4️⃣ Create a derived column: final_price after discount\n",
    "    # (assuming discount is percentage)\n",
    "    df[\"final_price\"] = df[\"price\"] * (1 - df[\"discount\"] / 100)\n",
    "\n",
    "    # 5️⃣ Sort alphabetically by category\n",
    "    df = df.sort_values(by=\"category\")\n",
    "\n",
    "    # 6️⃣ Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "print('Transformation function created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283fb90-249d-47c4-840d-3f621da901d0",
   "metadata": {},
   "source": [
    "## 4.3) Execute and Validate Clean function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a301cce-90f2-4149-9eb9-7612c4c221b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== BEFORE CLEANING =====\n",
      "Shape: (4362, 5)\n",
      "Missing values:\n",
      " Category    2748\n",
      "Price        174\n",
      "Rating      2050\n",
      "Stock       1352\n",
      "Discount     392\n",
      "dtype: int64\n",
      "Duplicates: 15\n",
      "\n",
      "Interim dataset saved to: C:\\Users\\DyFer\\Documents\\ELTE\\2Semester\\ITDS\\A01\\data-processing-pipeline\\assignment1\\data\\interim\\synthetic_dataset_interim.csv\n",
      "\n",
      "===== AFTER CLEANING =====\n",
      "Shape: (540, 5)\n",
      "Missing values:\n",
      " category    0\n",
      "price       0\n",
      "rating      0\n",
      "stock       0\n",
      "discount    0\n",
      "dtype: int64\n",
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# --- Before cleaning ---\n",
    "print(\"===== BEFORE CLEANING =====\")\n",
    "print(\"Shape:\", df_csv.shape)\n",
    "print(\"Missing values:\\n\", df_csv.isna().sum())\n",
    "print(\"Duplicates:\", df_csv.duplicated().sum())\n",
    "\n",
    "# --- Apply cleaning function ---\n",
    "df_clean = clean_mydata(df_csv)\n",
    "dataset_name = \"synthetic_dataset\"\n",
    "interim_path = DATA_INTERIM / f\"{dataset_name}_interim.csv\"\n",
    "df_clean.to_csv(interim_path, index=False)\n",
    "print(\"\\nInterim dataset saved to:\", interim_path)\n",
    "\n",
    "# --- After cleaning ---\n",
    "print(\"\\n===== AFTER CLEANING =====\")\n",
    "print(\"Shape:\", df_clean.shape)\n",
    "print(\"Missing values:\\n\", df_clean.isna().sum())\n",
    "print(\"Duplicates:\", df_clean.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765ce3f-600e-45df-930b-c6c5c6764f02",
   "metadata": {},
   "source": [
    "## 4.4) Execute Transformation function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bfab41d-e02f-494b-8e6c-b1eeb8396fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TRANFORMED DATA HEAD =====\n",
      "  category   price    rating         stock  discount  final_price\n",
      "0        A  7596.0  2.799564      In Stock      10.0      6836.40\n",
      "1        A  9116.0  2.160278      In Stock      45.0      5013.80\n",
      "2        A  4951.0  4.883903  Out of Stock      23.0      3812.27\n",
      "3        A  9854.0  2.694787  Out of Stock       3.0      9558.38\n",
      "4        A  9093.0  4.316502      In Stock       9.0      8274.63\n"
     ]
    }
   ],
   "source": [
    "df_transform = transformation_mydata(df_clean)\n",
    "\n",
    "dataset_name = \"synthetic_dataset\"\n",
    "processed_path = DATA_PROCESSED / f\"{dataset_name}_processed.csv\"\n",
    "df_transform.to_csv(processed_path, index=False)\n",
    "\n",
    "print(\"\\n===== TRANFORMED DATA HEAD =====\")\n",
    "print(df_transform.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e468eee-ff89-4f17-aaf6-5c19860d2130",
   "metadata": {},
   "source": [
    "# 5) Save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41c5115f-efbe-4e89-8ed1-eb007806fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary table saved to: C:\\Users\\DyFer\\Documents\\ELTE\\2Semester\\ITDS\\A01\\data-processing-pipeline\\assignment1\\reports\\summary_table.csv\n",
      "  category  total_products  avg_price  avg_final_price  avg_rating  \\\n",
      "0        A             130    4975.52          3727.09        3.07   \n",
      "1        B             143    5222.77          3952.31        3.04   \n",
      "2        C             131    5234.42          3834.47        3.00   \n",
      "3        D             136    5260.48          3947.12        3.14   \n",
      "\n",
      "   avg_discount  \n",
      "0         24.00  \n",
      "1         23.80  \n",
      "2         26.82  \n",
      "3         25.43  \n"
     ]
    }
   ],
   "source": [
    "# --- Create summary table grouped by category ---\n",
    "summary_table = (\n",
    "    df_transform\n",
    "    .groupby(\"category\")\n",
    "    .agg(\n",
    "        total_products=(\"category\", \"count\"),\n",
    "        avg_price=(\"price\", \"mean\"),\n",
    "        avg_final_price=(\"final_price\", \"mean\"),\n",
    "        avg_rating=(\"rating\", \"mean\"),\n",
    "        avg_discount=(\"discount\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Optional: round numeric values for cleaner reporting\n",
    "summary_table = summary_table.round(2)\n",
    "\n",
    "summary_path = REPORTS / \"summary_table.csv\"\n",
    "\n",
    "summary_table.to_csv(summary_path, index=False)\n",
    "\n",
    "print(\"Summary table saved to:\", summary_path)\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603c573-b78d-43e3-ba17-90f962972853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
